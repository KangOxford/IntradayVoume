{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# getting data from the one minute dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rollong mean of the volume"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# select which stock to be used in the analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top Trading Volume Stocks & AAPL & MGM & FITB & MPC & GS \\\\\n",
    "Bottom Trading Volume Stocks & AEP & HP & KLAC & GPN & ROK \\\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = ['AAPL', 'MGM','FITB','MPC','GS','AEP','HP','KLAC','GPN','ROK']\n",
    "for symbol in lst:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "docker build --build-arg UID=$UID --build-arg GIT_TOKEN=$GIT_TOKEN -t d345fn01 .\n",
    "docker run --name d345fn01 --user $(id -u) -v $(pwd):/homes/80/kang -it --gpus '\"device=3,4,5\"' d345fn01\n",
    "docker run -it -v /scratch/local/kang:/data d345fn01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /data\n",
    "touch run12feb.sh\n",
    "cat > run12feb.sh << 'EOF'\n",
    "input_dir=\"/data/\" # Directory containing .7z files\n",
    "sp500_dir=\"/homes/80/kang/SP500/\" # Directory to store all stock data directories \n",
    "\n",
    "# Define a list of stock names\n",
    "declare -a stock_list=('AAPL' 'MGM' 'FITB' 'MPC' 'GS' 'AEP' 'HP' 'KLAC' 'GPN' 'ROK')\n",
    "\n",
    "# Iterate over each .7z file in the input directory\n",
    "for file in \"$input_dir\"/*.7z; do\n",
    "    # Extract the stock name from the file name\n",
    "    stock_name=$(echo \"$file\" | grep -oP '(?<=__)\\w+(?=_)')\n",
    "\n",
    "    # Check if the extracted stock name is in the list\n",
    "    if [[ \" ${stock_list[@]} \" =~ \" ${stock_name} \" ]]; then\n",
    "        # Create directories for the stock data and its subdirectories\n",
    "        stock_dir=\"${sp500_dir}${stock_name}_data\"\n",
    "        mkdir -p \"$stock_dir/Book_10\" \"$stock_dir/Flow_10\"\n",
    "\n",
    "        # Unzip the file into a temporary directory\n",
    "        temp_dir=$(mktemp -d)\n",
    "        7z x \"$file\" -o\"$temp_dir\"\n",
    "\n",
    "        # Move files to appropriate subdirectories\n",
    "        for csv_file in \"$temp_dir\"/*.csv; do\n",
    "            if [[ $csv_file == *\"orderbook\"* ]]; then\n",
    "                mv \"$csv_file\" \"$stock_dir/Book_10/\"\n",
    "            elif [[ $csv_file == *\"message\"* ]]; then\n",
    "                mv \"$csv_file\" \"$stock_dir/Flow_10/\"\n",
    "            fi\n",
    "        done\n",
    "\n",
    "        # Remove the temporary directory\n",
    "        rm -r \"$temp_dir\"\n",
    "\n",
    "        # Move the stock directory into the SP500 directory\n",
    "        # mv \"$stock_dir\" \"$sp500_dir/\" # This line is not needed since \"$stock_dir\" already includes \"$sp500_dir\"\n",
    "    fi\n",
    "done\n",
    "EOF\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 76K\n",
      "drwxr-xr-x 4 kang        3509  82 Dec  7 15:40 AAL_data\n",
      "drwxr-xr-x 4 kang        3509  82 Dec  6 06:40 AAP_data\n",
      "drwxr-xr-x 4 kang        3509  48 Nov 27 14:19 AAPL_data\n",
      "drwxr-xr-x 4 kang        3509  48 Nov 27 14:30 ABBV_data\n",
      "drwxr-xr-x 4 kang        3509  82 Dec  7 09:09 ABC_data\n",
      "drwxr-xr-x 4 kang        3509  48 Nov 27 14:33 ABMD_data\n",
      "drwxr-xr-x 4 kang        3509  48 Nov 27 14:33 ABT_data\n",
      "drwxr-xr-x 4 kang        3509  82 Dec  7 04:01 ACN_data\n",
      "drwxr-xr-x 4 kang        3509  48 Nov 27 14:36 ADBE_data\n",
      "drwxr-xr-x 4 kang users        82 Jan 22 12:45 BAC_data\n",
      "drwxr-xr-x 4 kang        3509  48 Dec 10 03:01 CHD_data\n",
      "drwxr-sr-x 4 kang flair-users  48 Dec  7 09:31 CLX_data\n",
      "-rw-r--r-- 1 kang        3509 73K Dec  4 07:27 state_arrays_kang.pkl\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd /homes/80/kang/SP500/\n",
    "ls -lh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "(base) kang@flair-node-01:/scratch/local/kang/SP500$ du -lh\n",
    "7.6G    ./AEP_data/Book_10\n",
    "1.6G    ./AEP_data/Flow_10\n",
    "9.2G    ./AEP_data\n",
    "7.0G    ./GS_data/Book_10\n",
    "1.4G    ./GS_data/Flow_10\n",
    "8.4G    ./GS_data\n",
    "16G     ./FITB_data/Book_10\n",
    "3.0G    ./FITB_data/Flow_10\n",
    "19G     ./FITB_data\n",
    "0       ./HP_data/Book_10\n",
    "0       ./HP_data/Flow_10\n",
    "0       ./HP_data\n",
    "2.7G    ./GPN_data/Book_10\n",
    "579M    ./GPN_data/Flow_10\n",
    "3.3G    ./GPN_data\n",
    "0       ./KLAC_data/Book_10\n",
    "0       ./KLAC_data/Flow_10\n",
    "0       ./KLAC_data\n",
    "54G     ./AAPL_data/Book_10\n",
    "11G     ./AAPL_data/Flow_10\n",
    "64G     ./AAPL_data\n",
    "0       ./MGM_data/Book_10\n",
    "0       ./MGM_data/Flow_10\n",
    "0       ./MGM_data\n",
    "0       ./MPC_data/Book_10\n",
    "0       ./MPC_data/Flow_10\n",
    "0       ./MPC_data\n",
    "0       ./ROK_data/Book_10\n",
    "0       ./ROK_data/Flow_10\n",
    "0       ./ROK_data\n",
    "103G    ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = ['AEP','GS','FITB','GPN','AAPL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/scratch/local/kang/SP500'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## vwap file func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "def data_alignment(ATFolder):\n",
    "    '''\n",
    "    The logic here is to load the three dir: messages data, rolling mean and vwap\n",
    "    Then find the common_dates of all these three,\n",
    "    Then pass into the init of the base env, \n",
    "    To only load the data window in the common dates.\n",
    "    But we should also align the symbols, it has been done, as we will pass symbols \n",
    "    into the load_forecasted_and_original_volume_VWAP and load_forecasted_volume_RM\n",
    "    '''\n",
    "    def load_forecasted_and_original_volume_VWAP(symbol):\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "        dir = '/homes/80/kang/cmem/output/0900_r_output_with_features_csv_fractional_shares_clipped_vwap/'\n",
    "        df = pd.read_csv(dir+f'{symbol}.csv',index_col=0)\n",
    "        df['symbol'] = symbol\n",
    "        from datetime import datetime, timedelta\n",
    "        timeHMs = np.array([int((datetime(2023, 1, 1, 9, 30) + i * timedelta(minutes=15)).strftime('%H%M')) for i in range(26)])\n",
    "        timeHMs = np.tile(timeHMs, (1, int(df.shape[0]/timeHMs.shape[0]))).squeeze()\n",
    "        df['timeHMs'] = timeHMs\n",
    "        df = df[['date', 'timeHMs', 'x', 'qty', 'symbol']]\n",
    "        d = df[['date', 'timeHMs', 'x']].pivot(index = 'date', columns = 'timeHMs')\n",
    "        f = df[['date', 'timeHMs', 'qty']].pivot(index = 'date', columns = 'timeHMs')\n",
    "        return d, f # x, qty\n",
    "\n",
    "    def load_forecasted_volume_RM(symbol):\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "        dir = '/homes/80/kang/cmem/data/01_raw_rolling_mean_15min_bin/'\n",
    "        df = pd.read_csv(dir+f'{symbol}.csv',index_col=0)\n",
    "        df.columns = ['date', 'timeHMs', 'timeHMe', 'x_rm', 'symbol']\n",
    "        df.date = df.date.apply(lambda d: str(d)[:4]+'-'+str(d)[4:6]+'-'+str(d)[6:8]) if len(str(df.date[0])) == 8 else df.date\n",
    "        d = df[['date', 'timeHMs', 'x_rm']].pivot(index = 'date', columns = 'timeHMs')\n",
    "        d = d.fillna(method = \"ffill\")\n",
    "        return d # x\n",
    "\n",
    "    def load_files(symbol):\n",
    "        alphatradePath = ATFolder\n",
    "        # alphatradePath = f\"{ATFolder}/{symbol}_data\"\n",
    "        messagePath = alphatradePath+\"/Flow_10/\"\n",
    "        orderbookPath = alphatradePath+\"/Book_10/\"\n",
    "        from os import listdir; from os.path import isfile, join; import pandas as pd\n",
    "        readFromPath = lambda data_path: sorted([f for f in listdir(data_path) if isfile(join(data_path, f))])\n",
    "        messageFiles, orderbookFiles = readFromPath(messagePath), readFromPath(orderbookPath)\n",
    "        message_dates = np.array([m[4:14] for m in messageFiles])\n",
    "        message_dates = np.array([m.split(\"_\")[1] for m in messageFiles])\n",
    "        return message_dates\n",
    "    \n",
    "    def get_symbols():\n",
    "        from os.path import isdir\n",
    "        from os import listdir\n",
    "        path_dir1 = '/homes/80/kang/cmem/output/0900_r_output_with_features_csv_fractional_shares_clipped_vwap/'\n",
    "        path_dir2 = ATFolder\n",
    "        symbols1 = np.array([dirname.split(\".\")[0] for dirname in listdir(path_dir1)])\n",
    "        symbols2 = np.array([path_dir2.split(\"_\")[0].split(\"/\")[-1]])\n",
    "        # symbols2 = np.array([dirname.split(\"_\")[0] for dirname in listdir(path_dir2) \n",
    "        #             if isdir(os.path.join(path_dir2, dirname))])\n",
    "        intersection = np.intersect1d(symbols1, symbols2)\n",
    "        return intersection\n",
    "    common_stocks = get_symbols()\n",
    "    assert len(common_stocks) >= 1\n",
    "    \n",
    "    def get_raw_VWAPs_ORACLEs_RMs():\n",
    "        ds = [(symbol, *load_forecasted_and_original_volume_VWAP(symbol)) for symbol in common_stocks]\n",
    "        VWAPs = [(d[0], d[1]) for d in ds]\n",
    "        ORACLEs = [(d[0], d[2]) for d in ds]\n",
    "        RMs = [(symbol, load_forecasted_volume_RM(symbol)) for symbol in common_stocks]\n",
    "        return VWAPs, ORACLEs, RMs\n",
    "    VWAPs, ORACLEs, RMs = get_raw_VWAPs_ORACLEs_RMs()\n",
    "    \n",
    "    def get_common_dates():\n",
    "        dates_vwap =  VWAPs[-1][-1].index.to_numpy()\n",
    "        dates_rm =  RMs[-1][-1].index.to_numpy()\n",
    "        message_dates = load_files(common_stocks[-1]) \n",
    "        common_dates = np.intersect1d(np.intersect1d(dates_vwap, message_dates),dates_rm)\n",
    "        return common_dates\n",
    "    common_dates = get_common_dates()\n",
    "    \n",
    "    def align_dates(Xs):\n",
    "        Xs = {d[0]: d[1].loc[common_dates] for d in Xs}\n",
    "        return Xs\n",
    "    VWAPs, ORACLEs, RMs = list(map(align_dates, [VWAPs, ORACLEs, RMs]))\n",
    "\n",
    "    def generate_TWAPs(RMs):\n",
    "        def f(df):\n",
    "            dff = df.copy()\n",
    "            dff.loc[:, :] = 1\n",
    "            return dff\n",
    "        return {symbol: f(df) for symbol, df in RMs.items()}\n",
    "    TWAPs = generate_TWAPs(RMs)\n",
    "            \n",
    "    return common_dates, common_stocks, VWAPs, ORACLEs, RMs, TWAPs\n",
    "\n",
    "lst = ['AEP','GS','FITB','GPN','AAPL']\n",
    "symbol = 'AEP'\n",
    "ATFolder = f\"/scratch/local/kang/SP500/{symbol}_data\"\n",
    "# ATFolder = f\"/homes/80/kang/SP500/{symbol}_data\"\n",
    "# ATFolder = f\"/homes/80/kang/SP500/ABC_data\"\n",
    "# ATFolder = f\"/homes/80/kang/SP500/ACN_data\"\n",
    "# ATFolder = f\"/homes/80/kang/SP500/AAP_data\"\n",
    "common_dates, common_stocks, VWAPs, ORACLEs, RMs, TWAPs = data_alignment(ATFolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['AEP'], dtype='<U4'),\n",
       " array(['2017-07-20', '2017-07-21', '2017-07-24', '2017-07-25',\n",
       "        '2017-07-26', '2017-07-27', '2017-07-28', '2017-07-31',\n",
       "        '2017-08-01', '2017-08-02', '2017-08-03', '2017-08-04',\n",
       "        '2017-08-07', '2017-08-08', '2017-08-09', '2017-08-10',\n",
       "        '2017-08-11', '2017-08-14', '2017-08-15', '2017-08-16',\n",
       "        '2017-08-17', '2017-08-18', '2017-08-21', '2017-08-22',\n",
       "        '2017-08-23', '2017-08-24', '2017-08-25', '2017-08-28',\n",
       "        '2017-08-29', '2017-08-30', '2017-08-31', '2017-09-01',\n",
       "        '2017-09-05', '2017-09-06', '2017-09-07', '2017-09-08',\n",
       "        '2017-09-11', '2017-09-12', '2017-09-13', '2017-09-14',\n",
       "        '2017-09-15', '2017-09-18', '2017-09-19', '2017-09-20',\n",
       "        '2017-09-21', '2017-09-22', '2017-09-25', '2017-09-26',\n",
       "        '2017-09-27', '2017-09-28', '2017-09-29', '2017-10-02',\n",
       "        '2017-10-03', '2017-10-04', '2017-10-05', '2017-10-06',\n",
       "        '2017-10-10', '2017-10-11', '2017-10-12', '2017-10-13',\n",
       "        '2017-10-16', '2017-10-17', '2017-10-18', '2017-10-19',\n",
       "        '2017-10-20', '2017-10-23', '2017-10-24', '2017-10-25',\n",
       "        '2017-10-26', '2017-10-27', '2017-10-30', '2017-11-01',\n",
       "        '2017-11-02', '2017-11-03', '2017-11-06', '2017-11-07',\n",
       "        '2017-11-08', '2017-11-09', '2017-11-10', '2017-11-13',\n",
       "        '2017-11-14', '2017-11-15', '2017-11-16', '2017-11-17',\n",
       "        '2017-11-20', '2017-11-21', '2017-11-22', '2017-11-27',\n",
       "        '2017-11-28', '2017-11-29', '2017-11-30', '2017-12-01',\n",
       "        '2017-12-04', '2017-12-05', '2017-12-06', '2017-12-07',\n",
       "        '2017-12-08', '2017-12-11', '2017-12-12', '2017-12-13',\n",
       "        '2017-12-14', '2017-12-15', '2017-12-18', '2017-12-19',\n",
       "        '2017-12-20', '2017-12-21', '2017-12-22', '2017-12-26',\n",
       "        '2017-12-27'], dtype=object))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_stocks, common_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstsymbols = ['AEP','GS','FITB','GPN','AAPL']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run r to get the cmem results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/homes/80/kang/cmem/data_minmax/02.2_data_r_input_kf_minmax\n"
     ]
    }
   ],
   "source": [
    "cd /homes/80/kang/cmem/data_minmax/02.2_data_r_input_kf_minmax/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/homes/80/kang/cmem/data_minmax/02.2_data_r_input_kf_minmax/'\n",
    "from os import listdir\n",
    "lst = listdir(path)\n",
    "lstt = [file[:-4] for file in lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 AAPL\n",
      "16 AEP\n",
      "174 FITB\n",
      "196 GPN\n",
      "199 GS\n"
     ]
    }
   ],
   "source": [
    "for idx, itm in enumerate(lstt):\n",
    "    if itm in lstsymbols:\n",
    "        print(idx, itm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## use this r code:\n",
    "/homes/80/kang/cmem/rkf_fraction.r\n",
    "## hers is the output dir\n",
    "/homes/80/kang/cmem/output/0400_r_kl_output_raw_data_minmax/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check whether all the data is generated correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    472     472    3833\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd /homes/80/kang/cmem/output/0400_r_kl_output_raw_data_minmax/\n",
    "ls | wc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  note the data might not all generated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# we have to generate this after the r code output: \n",
    "0900_r_output_with_features_csv_fractional_shares_clipped_vwap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get symbol  codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "472"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir = '/homes/80/kang/cmem/output/0400_r_kl_output_raw_data_minmax/'\n",
    "import os \n",
    "from os import listdir\n",
    "lst = sorted([file[:-4] for file in listdir(dir)])\n",
    "len(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/homes/80/kang/cmem/stock_names.txt'\n",
    "reloaded_stock_names = []\n",
    "with open(file_path, 'r') as f:\n",
    "    reloaded_stock_names = [line.strip() for line in f.readlines()]\n",
    "reloaded_stock_names,len(reloaded_stock_names)\n",
    "lst = reloaded_stock_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### from mihai's shares outstanding data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "dir0 = \"/homes/80/kang/2017daily_csv/\"\n",
    "onlyFiles = sorted([f for f in listdir(dir0) if isfile(join(dir0, f))])\n",
    "dfflst =[]\n",
    "i=0\n",
    "# for i in range(len(onlyFiles)):\n",
    "print(i)\n",
    "name = onlyFiles[i]\n",
    "import pandas as pd\n",
    "# name =\"CMS.csv\"\n",
    "\n",
    "dir = dir0+name\n",
    "df = pd.read_csv(dir)\n",
    "mhlst = sorted(df.ticker.to_list())\n",
    "len(mhlst)\n",
    "lstt = [file for file in mhlst if file in lst]\n",
    "len(lstt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst0=[file for file in lst if file not in lstt]\n",
    "len(lst0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lst0 is the missing parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A',\n",
       " 'AAPL',\n",
       " 'ADBE',\n",
       " 'ADSK',\n",
       " 'AKAM',\n",
       " 'ALGN',\n",
       " 'ALXN',\n",
       " 'AMAT',\n",
       " 'AMGN',\n",
       " 'AMZN',\n",
       " 'ANSS',\n",
       " 'ATVI',\n",
       " 'AVGO',\n",
       " 'BF.B',\n",
       " 'BIIB',\n",
       " 'BRK.B',\n",
       " 'CBOE',\n",
       " 'CDW',\n",
       " 'CERN',\n",
       " 'CHRW',\n",
       " 'CHTR',\n",
       " 'CINF',\n",
       " 'CMCSA',\n",
       " 'COST',\n",
       " 'CPRT',\n",
       " 'CSCO',\n",
       " 'CTAS',\n",
       " 'CTSH',\n",
       " 'CTXS',\n",
       " 'DISCA',\n",
       " 'DISCK',\n",
       " 'DISH',\n",
       " 'DLTR',\n",
       " 'EA',\n",
       " 'EBAY',\n",
       " 'EQIX',\n",
       " 'EXPD',\n",
       " 'EXPE',\n",
       " 'FANG',\n",
       " 'FAST',\n",
       " 'FFIV',\n",
       " 'FISV',\n",
       " 'FITB',\n",
       " 'FLIR',\n",
       " 'FTNT',\n",
       " 'GILD',\n",
       " 'GOOG',\n",
       " 'GOOGL',\n",
       " 'GRMN',\n",
       " 'HBAN',\n",
       " 'HOLX',\n",
       " 'HSIC',\n",
       " 'IDXX',\n",
       " 'ILMN',\n",
       " 'INTC',\n",
       " 'INTU',\n",
       " 'IPGP',\n",
       " 'ISRG',\n",
       " 'JBHT',\n",
       " 'JKHY',\n",
       " 'KHC',\n",
       " 'KLAC',\n",
       " 'LKQ',\n",
       " 'LRCX',\n",
       " 'MCHP',\n",
       " 'MKTX',\n",
       " 'MNST',\n",
       " 'MSFT',\n",
       " 'MXIM',\n",
       " 'NDAQ',\n",
       " 'NFLX',\n",
       " 'NTAP',\n",
       " 'NTRS',\n",
       " 'NVDA',\n",
       " 'NWSA',\n",
       " 'ODFL',\n",
       " 'ORLY',\n",
       " 'PAYX',\n",
       " 'PBCT',\n",
       " 'PCAR',\n",
       " 'PYPL',\n",
       " 'QCOM',\n",
       " 'QRVO',\n",
       " 'REGN',\n",
       " 'ROST',\n",
       " 'SBAC',\n",
       " 'SBUX',\n",
       " 'SIVB',\n",
       " 'SNPS',\n",
       " 'SWKS',\n",
       " 'TRIP',\n",
       " 'TROW',\n",
       " 'TSCO',\n",
       " 'TTWO',\n",
       " 'ULTA',\n",
       " 'VRSK',\n",
       " 'VRSN',\n",
       " 'VRTX',\n",
       " 'WYNN']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "x",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
